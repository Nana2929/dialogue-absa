# reference: https://tsmatz.wordpress.com/2022/11/25/huggingface-japanese-summarization/
# Note : Do not use FP16 precision in mT5 fine-tuning.
seed: 42
data:
#   data_root: 'data/diaasq/speaker_dataset'
#   train_split_name: 'train'
#   test_split_name: 'valid'
  lang_src : 'en'

# proc_data and dataset follows the diaasq-t5-speaker-spec-en.yaml for experiment comparison
proc_data:
  type: 'speaker'
  data_root: 'data/diaasq/speaker_dataset/proc'
  train_ic_name: 't5_in_context' # use t5/create_kshot_dataset_split.py
  t5_train_split_name: 't5_train'
  test_ic_name: 't5_in_context'  # use the same in-context examples as in training
  t5_test_split_name: 't5_valid'

dataset:
  name: 'diaasq-speaker-spec-en'
  k: 1
  prompt_path: 'prompt/experiment/diaasq-speaker-spec-en-t5'
  in_context_strategy: None

model:
  model_name: 'gpt-3.5-turbo'
  max_tokens: 256 # t5: generation_max_length: 256 # t5: # max_length: 512
  temperature: 0

# private keys
envfile: './envs/.env'
output_dir: './results'






